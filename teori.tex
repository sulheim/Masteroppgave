%Teori.tex
\section{Theory}
\subsection{A start}
The basis of ultrasound imaging is the reflection of ultrasound at tissue boundaries within the body. The ultrasound is generated by a transducer, and as the wave travels through the body an echo is generated by partial reflection at every boundary. The amount of reflection depends on the difference in acoustic impedance. The echo is recorded by the transducer, and it is then displayed in the image according its spatial origin. The speed of sound is approximately \SI{1540}{\metre\per\second} for all soft tissue in the body, and it is thus easy to calculate the origin by measuring the time of travel of the echo.  The brightness in the image is proportional to the strength of the echo, and this is thus called B-mode(brightness mode). 



\subsection{Contrast agents}
Contrast agents are used to increase the image sensitivity, by increasing image contrast between the relevant body tissues. In ultrasound imaging, this is accomplished by injecting a solution containing gas-filled microbubbles. 

The first contrast agents were made by saline, and was put to use by cardiologists in the 1960s for identification of mitral valve echoes. The saline was shaken before injection to create the microbubbles. Current available contrast agents are more complex, and consist of a carefully chosen gas enclosed in a suited shell. The shell has to be biocompatible and is made from fat or proteins. The advantage of a shell is increased lifetime and scattering of ultrasound. The size of the microbubbles is approximately equal to the size of red blood cells (\SIrange{2}{6}{\micro\metre}), and flow easily through the circulatory system. 

The microbubbles have two important properties which cause large scattering. The first reason is the big difference in acoustic impedance between microbubbles and human tissue. The second property is the compressability of the gas inside the microbubble. The pressure fluctuations caused by the ultrasound forces the microbubble to expand during rarefaction and contract during compression. The microbubble will oscillate with the same frequency as the ultrasound source, and the scattering will be strongest at the resonance frequency of the microbubble. The resonant frequency is determined by the properties and the size of the shell. 

\subsection{Our Bubble}
\subsection{Transducer}

\subsection{Image processing of B-mode images}
After the echoes have reached the transducer a signal is produced by making an image with the brightness at each pixel determined by the strength of the echo from that corresponding distance and direction. The first step in the image processing is to convert the signal from analogue to digital. The digital signal is less vulnerable to noise and distortion, and it enables further digital image processing. Then a linear amplifier apply the same amount of gain to the entire signal, to make the signal strong enough for further processing. Time-gain compensation is then applied to make echoes from similar interfaces equal, regardless of the depth of their origin. This is performed by increasing the gain with increasing depth of echo. The depth of the echo is identified by the arrival time at the transducer. The rate of attenuation of ultrasound with depth is determined by the frequency and tissue.

After amplification and time-gain compensation the dynamic range of the signal is about 60 dB. The dynamic range of a signal is defined as the ratio between the largest amplitude that can be recorded without causing distortion and the lowest amplitude that can be distinguished from noise. The dynamic range of a common screen is about 20 dB. The signal must therefore be compressed before it can be displayed. To compress the dynamic range from 60 to 20 dB, an amplifier with non-linear gain is applied. Low amplitudes are amplified more than high, and the dynamic range is therefore decreased. Compression allows weak echoes from scattering within tissue to be displayed together with strong echoes from tissue interfaces.

\subsubsection{RF and IQ data}
RF is short term for radio frequency data which is used in ultrasound as a description for unprocessed data. IQ is short term for in quadrature, and refers to a demodulation of the RF signal to reduce the amount of storage space without loss of information. IQ modulation converts the signal from the real to the imaginary space. The IQ signal is obtained using a IQ-demodulator to down-mix, low-pass filter and decimate the RF signal. The IQ signal can also be computed by through a Hilbert transform\cite{Kirkhorn1999}.

\subsubsection{Hilbert transform}
The Hilbert transform is a linear operator which acts on a signal $u(t)$ to derive an analytic signal. The Hilbert transform convert the signal from real to complex space by adding or subtracting 90 degrees. It is therefore also known as a phase-shift operator. An analytic signal has by definition only positive frequencies in its Fourier transform, and is related to the Hilbert transform through 

\begin{equation}
\tilde{x}(t) = x(t) + x_h(t),
\end{equation}

where $x(t)$ is the signal, $x_h(t)$ the Hilbert transform of the signal, and $\tilde{x}(t)$ the analytic signal. The Hilbert transform can be written as a convolution, 

\begin{equation}
x_h(t) = x(t)*\frac{1}{\pi t},
\end{equation}

which can be interpreted as a filtering operation with a quadrature filter which shifts all sinusoidal components by a phase shift of $\frac{\pi}{2}$. The envelope is the amplitude of the analytic signal, and a B-mode image is created from the envelope of the signal. 

\subsubsection{Downsampling}
Because it is the envelope that is used to create the B-mode images, further reduction in data size can be achieved by downsampling of the RF signal. The RF signal is downsampled by a decimation factor $M$, by only recording every $M$th sample. 

The RF signal is a strictly bandlimited signal, limited by the bandwidth of the transducer. The envelope is thus also a bandlimited signal, with a finite maximum frequency. According to the Nyquist-Shannon sampling theorem, this signal can be sampled without aliasing or loss of information by a sampling rate twice the maximum frequency. Hence, the decimation factor, $M$, is determined so that

\begin{equation}
\label{deciamtion}
\fraction{Fs_{RF}}{M} > 2f^{max}_{envelope},
\end{equation}

where ${Fs_{RF}$ is the sampling frequency of the RF signal, and $f^{max}_{envelope}$ is the maximum frequency of the envelope. For a thorough explanation, see \cite{Crochiere1981}.



\subsection{Harmonic Imaging}

\subsection{Matlab}
The most important to write here is how the methods used in matlab work IN THEORY, not how they are implemented in MATLAB.


\subsubsection{Removing image artifacts}
The operation of removing movement artifacts are based on the Matlab toolbox Image Processing and the use of image registration. \textit{imregister} and \textit{imregconfig} are the first two functions that have been applied and tested. This is intensity based automatic registration. Control point registration may be another option.

DETTE ER KANSKJE IKKE VIKTIG
The process is initiated by making a \textit{metric} and an \textit{optimizer} object using the \textit{imregconfig} function. The \textit{metric} object measures the similarity of the two images. The \textit{optimizer} contains the optimization parameters such as maximum number of iterations, initial step length, optimization algorithm etc. Which optimization algorithm and how the image similarity is measured can be chosen in the \textit{imregconfig} function. The options for optimization algorithm are either a regular step gradient or a one-plus-one evolutionary method. For the metric object the similarity can be measured either by a mean square error approach or by making a mutual information metric. The mutual information metric maximizes the number of pixel with the same relative pixel value, and is best suited for images with different brightness ranges.[REF MATLAB]

\subsection{Speckle}
Speckle is a random, deterministic speckle pattern present in all types of coherent imaging, thus also in ultrasound images. The speckle is formed by scatterers smaller than the resolution of the imaging system, and the shape and size of the speckle pattern is determined by the dimensions of the imaging system and the structure of the imaged tissue.

The speckle is an interference phenomenon created by coherent waves with different phase and amplitude added together. If several echo waves arrive at the same piezoelectric element within a time span shorter than the emitted pulse, the piezoelectric element will not be able to distinguish the waves, and their impact will be added. 

\subsection{Image registration}
Image registration is the process where one image is spatially aligned to a reference image. The image to be aligned is called the moving image, while the reference image is called the fixed image. Image registration  is an important part of image processing and can both be used to remove motion artifacts or to fuse images of the same object, captured with different image modalities or from different directions. 

Image registration can initially be divided into extrinsic and intrinsic methods. Extrinsic methods are based on foreign objects placed into the scene before the image is captured. This has the advantage of simple, feature-based registration, but the preplacement and removal of these objects may not be trivial. 

Intrinsic methods can be divided into feature and intensity based registration. Features can either be easily recognizable points identified by the user, or structures which can be extracted from the image by image segmentation. These methods are mostly used in rigid transformations, and have the advantage of being simple computations once the features are determined. One drawback is that the registration often is limited by the reliability of the segmentation or identification of the features. Although these methods are applicable to both multi- and monomodal registration, and to different body parts, their use have in general been limited to neuroimaging and orthopedic imaging\cite{Maintz1998}.

Intensity based registration differs from the other methods by using the intensity pixel values directly to compare the fixed and moving image. To compare the images a suited similarity measure is used, see section\ref{subsec:similarity}. Using different similarity measures, this method is suitable for both multi- and monomodal registration. The image registration is then performed using an optimization routine to find the spatial translation of the moving image which minimizes the chosen similarity measure. Choosing the right similarity measure and optimization scheme is essential to get a satisfying result. For a full review of this topic, see \cite{Maintz1998}.

\subsubsection{Basic theory of image registration}
\cite{Mainstream}
%Should non-parametric transformations be mentioned?

%Transformation of an image is the basis for image registration, and can be described as a function $y$ mapping the image coordinates from $\Real_d \arrow \Real_d$ using a linear combination of basis functions and coefficients.

\subsubsection{Image transformations}

Transformation of an image is the basis for image registration, and can be described as a mapping of a coordinate vector $\vec{x}$ from the space $X$ to a new coordinate vector $\vec{y}$ in the space $Y$. The transformation is performed by a transformation matrix $A$, i.e. $\vec{y} = A\vec{x}$.

In 2D a rigid transformation can be written as 

\begin{equation}
	\label{rigid}
	\begin{pmatrix}
		y_1 \\
		y_2 \\
		1 
	\end{pmatrix}
	=
	\begin{pmatrix}
		R_{11} & R_{12} & T_1\\
		R_{21} & R_{22} & T_2\\		
		0 & 0 & 1
	\end{pmatrix}
	\begin{pmatrix}
		x_1\\
		x_2\\
		1
	\end{pmatrix},
\end{equation}
where $R_{ij}$ are elements in the rotation matrix 

\begin{equation}
	R = 
	\begin{pmatrix}
	\cos \theta & -\sin \theta\\
	\sin \theta & \cos \theta
	\end{pmatrix}.
\end{equation}
The rotation matrix rotates the coordinates an angle $\theta$ around the origo. The matrix elements $T_{ij}$ determines the translation of the coordinates. An affine translation is described by the matrix 
\begin{equation}
\begin{pmatrix}
 a_{11}&a_{12}&a_{13}\\
 a
 
\end{pmatrix}
\end{equation} This enables shear and scaling of the image.

If we apply a transformation matrix to an image, we get the new pixel coordinates of transformed image, but these points will not be on the grid coordinates of the image. For that reason, an interpolation scheme is applied to the transformed image coordinates to get the new pixel values at the grid coordinates. A suitable interpolation scheme must be chosen according to the given problem, but the most common are described in section ??????

Image transformation can be divided into linear and non-linear transformation. For a linear transformation the same transformation matrix is applied to the whole image, whereas this is not the case for a non-linear transformation. Linear transformation is computationally faster and simpler, and less affected by noise. On the other hand, non-linear transformations can correct for local deformations out of reach for the linear transformation. 

The difficult part of image registration is not to apply the transformation, but to obtain the right transformation matrix. The simplest case is the point or feature based method, where easily recognized feature are localized in both the fixed and moving image, either by interaction from the user, or by using a feature detection algorithm. In the case of an affine transformation, six pair of corresponding coordinates are needed to solve the set of linear equations to obtain the the six unknown elements in the transformation matrix. Usually, more points are obtained, and the transformation matrix is calculated using a least-squares approach. 

\subsubsection{Similarity measure}
\label{subsec:similarity}
There are several ways of measuring the similarity between two images, where different approaches enhance different image properties, and are suitable for different problems. The choice of similarity measure will determine the minimum and the rate of convergence for the optimization scheme.

When the images to compare are from the same modality, they will be in the same intensity range. They will only differ because of noise, geometric transformation and changes in imaged object. Common similarity measures are then the sum of squared differences (SSD), the sum of absolute differences or the cross correlation. If the changes in the imaged object is sufficiently small, and we assume the noise to be Gaussian, it is shown in \cite{Viola1997} that SSD give the optimal result.
For two images $A$ and $B$ the SSD is given as
\begin{equation}
\label{SSD}
\mathrm{SSD} = \frac{1}{N}\sum_{i}^N \abs{A_i -B_i}^2, \forall i \in A \cap B,   
\end{equation}

where $i$ is an image pixel. 

In multimodal image registration, the images have neither similar intensities or even a linear relationship between the intensities. For this type of problems, mutual information is the most common similarity measure. Mutual information is a measure of the statistical dependence of the two images, and the alignment is optimal the moving image contains the maximal amount of information about the fixed image. For a detailed review of mutual information in medical multimodal imaging, see \cite{563664}.  

\subsection{Regular step gradient descent}
An optimization scheme determines the optimal alignment by optimizing the chosen similarity measure. The optimization scheme is usually chosen through an empirical approach, where computational demand, reliability and stability are important factors. 

The gradient descent method is a first-order algorithm which finds the local minimum of a multivarible, differentiable function $F(x)$. From a given initial state $x_k$, the optimizer moves a distance $\gamma$ in the direction opposite to the gradient, i.e.

\begin{equation}
\label{gradient descent}
x_{k+1} = x_k - \gamma \Delta F(x_k).
\end{equation}

This method suffers from the reliability of the step distance $\gamma$. Too long or short step will give a slow, or no convergence. The \italic{regular step gradient descent} is a variation where the step length is halved every time there is a significant change in the direction of the gradient. The optimization terminates after reaching a the minimum, at a minimum step length, or after a maximum number of iterations.

To speed up the image registration, a pyramidal method can be applied together with the gradient descent. A smoothing filter is applied to the images, before they are decimated by a factor 2. This is performed for a given number of pyramid levels, resulting in a set of images with decreasing size. The scheme starts by optimizing the translation for the smallest image, and the optimal translation is used as an initial translation in the next pyramid level. In addition the increased speed, there is also less chance of getting stuck in a local minimum due to the smoothing which is applied before each decimation.
 








